{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CatsVsDogs_RF.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNRtpxP41ksuppxwGCkP7h7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3pRAgePyY0Wu"},"source":["# Welcome!\n","In this example, we will use a random forest model to classify an animal as a cat or a dog given certain features. The dataset that we used will be linked, so you can upload that a similar collab notebook if you want to follow along. This notebook will be split into **4 parts**:\n","\n","\n","1.   Preparing the data\n","2.   Making the model\n","3.   Training our model with the processed data\n","4.  Testing our model by having it make predictions on new data \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P6JrkPKIYStn"},"source":["### 1. Preparing the data\n","Using pandas and numpy we will process the CatsVsDogs.csv file so its data can be used in our random forest model"]},{"cell_type":"code","metadata":{"id":"uvhxyyf1XWez","executionInfo":{"status":"ok","timestamp":1619932676113,"user_tz":420,"elapsed":336,"user":{"displayName":"Athreya Daniel","photoUrl":"","userId":"00834539549929852477"}}},"source":["#importing the libraries we will be using to process the data - pandas and numpy\n","import pandas as pd\n","from sklearn import *"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"uNUCRhA0YRfU","executionInfo":{"status":"ok","timestamp":1619932676285,"user_tz":420,"elapsed":489,"user":{"displayName":"Athreya Daniel","photoUrl":"","userId":"00834539549929852477"}},"outputId":"2a459276-5f58-4174-8d1f-f630f7f441e8"},"source":["#taking a look at the structure of the csv file we have\n","df = pd.read_csv(\"sample_data/CatsVsDogs.csv\")\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Whiskers</th>\n","      <th>Large Teeth</th>\n","      <th>Likes Milk</th>\n","      <th>Loud</th>\n","      <th>Cat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Whiskers  Large Teeth  Likes Milk  Loud  Cat\n","0         1            0           1     0    1\n","1         0            1           0     1    0\n","2         1            0           1     0    1\n","3         0            1           0     1    0\n","4         1            0           1     0    1"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"BxigUFhCeMNX","executionInfo":{"status":"ok","timestamp":1619932676286,"user_tz":420,"elapsed":481,"user":{"displayName":"Athreya Daniel","photoUrl":"","userId":"00834539549929852477"}}},"source":["#separating the training data into train and test features\n","X = df.iloc[:,0:4].values\n","y = df.iloc[:,4].values"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uiFUu37eo35","executionInfo":{"status":"ok","timestamp":1619932676287,"user_tz":420,"elapsed":479,"user":{"displayName":"Athreya Daniel","photoUrl":"","userId":"00834539549929852477"}}},"source":["#making an 80/20 train-test split for the data\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ejtw1RmcfBfr"},"source":["###2. Making the Model\n","We will use sklearn's inbuilt random forest model"]},{"cell_type":"code","metadata":{"id":"sVCWpyQBfFAL","executionInfo":{"status":"ok","timestamp":1619932676287,"user_tz":420,"elapsed":477,"user":{"displayName":"Athreya Daniel","photoUrl":"","userId":"00834539549929852477"}}},"source":["#importing the Random Forest model\n","from sklearn.ensemble import RandomForestClassifier\n","\n","#creating the random forest object with 30 trees (as indicated by the n_estimators param)\n","classifier = RandomForestClassifier(n_estimators=30)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rbM6yEHFfxYr"},"source":["###3. Training the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcA_Uctgf06J","executionInfo":{"status":"ok","timestamp":1619932676288,"user_tz":420,"elapsed":470,"user":{"displayName":"Athreya Daniel","photoUrl":"","userId":"00834539549929852477"}},"outputId":"76bd5739-7167-4e7c-c866-0b8f9772190a"},"source":["#fitting the model to our training data\n","classifier.fit(X_train, y_train)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=30,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"OMSkAq_6gCB_"},"source":["###4. Testing and evaluating the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaDPzrWlf-vi","executionInfo":{"status":"ok","timestamp":1619932676289,"user_tz":420,"elapsed":464,"user":{"displayName":"Athreya Daniel","photoUrl":"","userId":"00834539549929852477"}},"outputId":"87f8efda-3628-493d-9e59-dba9c54d2433"},"source":["import numpy as np\n","\n","#making prediction on our test data\n","y_pred = classifier.predict(X_test)\n","results = []\n","#merging X_test and y_pred in new array res to add to dataframe\n","for i in range(0,4):\n","  results.append(np.append(X_test[i],y_pred[i]))\n","\n","#visualizing results in a new dataframe\n","r_df = pd.DataFrame(data = results, columns = [\"Whiskers\",\"Large Teeth\",\"Likes Milk\",\"Loud\",\"Cat\"])\n","print(r_df.head())\n","\n","#looking at our results\n","from sklearn.metrics import accuracy_score\n","print(str(accuracy_score(y_test, y_pred)*100) + \"% accuracy rate\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["   Whiskers  Large Teeth  Likes Milk  Loud  Cat\n","0         1            0           1     0    1\n","1         0            1           0     1    0\n","2         1            0           1     0    1\n","3         0            1           0     1    0\n","100.0% accuracy rate\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CvRvOQRMlruu"},"source":["###Conclusions\n","\n","\n","*   Our model performed extraordinarily well on the data (however data will **almost never** be this perfect though)\n","*   In general, anything over a 98% accuracy rate is sufficient, so we will not have to finetune our parameters for the model this time\n","*   You could try this approach on other datasets as well, and tweak parameters such as the number of estimators (number of trees in the model)\n","\n","\n","\n","\n"]}]}